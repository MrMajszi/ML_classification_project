{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7ab4066",
   "metadata": {},
   "source": [
    "LOADING DEPENDENCIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f75f99dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    cross_val_score, \n",
    "    GridSearchCV)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import (\n",
    "    LinearRegression,\n",
    "    LogisticRegression,\n",
    "    LogisticRegressionCV,\n",
    "    Lasso,\n",
    "    Ridge,\n",
    "    ElasticNet\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    median_absolute_error,\n",
    "    mean_absolute_percentage_error,\n",
    "    r2_score,\n",
    "    make_scorer,\n",
    "    accuracy_score, \n",
    "    classification_report\n",
    ")\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.model_selection import (\n",
    "    KFold,\n",
    "    ShuffleSplit,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    RandomizedSearchCV,\n",
    "    GridSearchCV\n",
    ")\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import scipy.stats as sc\n",
    "from scipy.stats import uniform\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b333f4bb",
   "metadata": {},
   "source": [
    "LOADING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b9570fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_full=pd.read_csv(\"data/output/train_full.csv\")\n",
    "x_train=pd.read_csv(\"data/output/train.csv\")\n",
    "x_test=pd.read_csv(\"data/output/test.csv\")\n",
    "x_val=pd.read_csv(\"data/output/validation.csv\")\n",
    "\n",
    "\n",
    "y_train_full=pd.read_csv(\"data/output/target_train_full.csv\")\n",
    "y_train=pd.read_csv(\"data/output/target_train.csv\")\n",
    "y_test=pd.read_csv(\"data/output/target_test.csv\")\n",
    "y_val=pd.read_csv(\"data/output/target_validation.csv\")\n",
    "\n",
    "df_train=pd.read_csv(\"data/output/train_with_target.csv\")\n",
    "df_test=pd.read_csv(\"data/output/test_with_target.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49aaa999",
   "metadata": {},
   "source": [
    "LOGISTIC REGRESSION- MODEL PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f37b70ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Skicit library\n",
    "scaler = StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "x_train_scaled= scaler.fit_transform(x_train)\n",
    "x_val_scaled=scaler.fit_transform(x_val)\n",
    "x_test_scaled = scaler.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4ddde90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:(83123, 22), y_train shape:(83123, 1)\n",
      "x_test shape:(25976, 22),y_test shape:(25976, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"x_train shape:{x_train_scaled.shape}, y_train shape:{y_train.shape}\")\n",
    "print(f\"x_test shape:{x_test_scaled.shape},y_test shape:{y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d3cb80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.98577303  0.47279025  0.66865705 ... -0.44925192  1.38756185\n",
      "   0.24036482]\n",
      " [-0.98577303  0.47279025 -1.49553498 ... -0.44925192  0.82266227\n",
      "  -1.5488098 ]\n",
      " [-0.98577303 -2.11510282  0.66865705 ... -0.44925192 -0.08071464\n",
      "  -1.0849496 ]\n",
      " ...\n",
      " [-0.98577303 -2.11510282  0.66865705 ...  0.36450628  0.45048379\n",
      "  -1.2174811 ]\n",
      " [ 1.0144323   0.47279025  0.66865705 ... -0.44925192  1.21823719\n",
      "  -0.8861525 ]\n",
      " [-0.98577303 -2.11510282  0.66865705 ... -0.31905061 -0.13979026\n",
      "  -1.2837468 ]]\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(penalty=None)\n",
    "print(x_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "740cea2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(penalty=None)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(penalty=None)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(penalty=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(x_train_scaled , y_train.to_numpy().ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "355827b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8744029931547225"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(x_train_scaled , y_train.to_numpy().ravel()) #score on train quite decent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbf1d5a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8743070526639976"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(x_test_scaled , y_test.to_numpy().ravel()) #pretty similar output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93c5a313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y_test</th>\n",
       "      <th>Y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Y_test  Y_pred\n",
       "0        0       0\n",
       "1        1       1\n",
       "2        0       0\n",
       "3        1       1\n",
       "4        0       0\n",
       "5        0       0\n",
       "6        1       1\n",
       "7        0       1\n",
       "8        1       1\n",
       "9        0       0\n",
       "10       0       0\n",
       "11       1       0\n",
       "12       0       0\n",
       "13       0       0\n",
       "14       1       1\n",
       "15       0       0\n",
       "16       1       1\n",
       "17       0       0\n",
       "18       1       0\n",
       "19       0       0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = lr.predict(x_test_scaled)\n",
    "data = pd.DataFrame({\"Y_test\" : y_test.Satisfaction , \"Y_pred\": Y_pred})\n",
    "data.head(20) #still we can see even in this batch some FP and FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64e02af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.347744\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:           Satisfaction   No. Observations:                83123\n",
      "Model:                          Logit   Df Residuals:                    83101\n",
      "Method:                           MLE   Df Model:                           21\n",
      "Date:                Mon, 13 Jan 2025   Pseudo R-squ.:                  0.4920\n",
      "Time:                        19:38:15   Log-Likelihood:                -28905.\n",
      "converged:                       True   LL-Null:                       -56903.\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.0453      0.011      4.263      0.000       0.024       0.066\n",
      "x2             0.7881      0.012     64.595      0.000       0.764       0.812\n",
      "x3             1.2320      0.015     81.454      0.000       1.202       1.262\n",
      "x4             0.3231      0.013     24.785      0.000       0.298       0.349\n",
      "x5            -0.1833      0.013    -13.892      0.000      -0.209      -0.157\n",
      "x6            -0.2875      0.017    -16.582      0.000      -0.321      -0.253\n",
      "x7             0.4168      0.012     35.331      0.000       0.394       0.440\n",
      "x8             0.8735      0.015     56.987      0.000       0.843       0.904\n",
      "x9             0.0945      0.012      7.625      0.000       0.070       0.119\n",
      "x10            0.3821      0.014     27.410      0.000       0.355       0.409\n",
      "x11            0.0935      0.016      5.836      0.000       0.062       0.125\n",
      "x12            0.3631      0.012     30.649      0.000       0.340       0.386\n",
      "x13            0.2927      0.018     16.308      0.000       0.258       0.328\n",
      "x14           -0.0687      0.016     -4.272      0.000      -0.100      -0.037\n",
      "x15            0.1534      0.015     10.115      0.000       0.124       0.183\n",
      "x16            0.4597      0.017     26.922      0.000       0.426       0.493\n",
      "x17            0.1075      0.021      5.187      0.000       0.067       0.148\n",
      "x18            0.1844      0.014     12.750      0.000       0.156       0.213\n",
      "x19           -0.3266      0.033     -9.832      0.000      -0.392      -0.261\n",
      "x20            0.1215      0.033      3.664      0.000       0.056       0.186\n",
      "x21           -0.0002      0.012     -0.019      0.985      -0.023       0.023\n",
      "x22           -0.1098      0.011     -9.676      0.000      -0.132      -0.088\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "#Statsmodel library\n",
    "log_reg = sm.Logit(y_train.Satisfaction, x_train_scaled).fit() \n",
    "\n",
    "# Print the model summary\n",
    "print(log_reg.summary()) #Flight distance (x21) as statistically insignificant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fad6f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89     14662\n",
      "           1       0.87      0.83      0.85     11314\n",
      "\n",
      "    accuracy                           0.87     25976\n",
      "   macro avg       0.87      0.87      0.87     25976\n",
      "weighted avg       0.87      0.87      0.87     25976\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,Y_pred)) #classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c16786e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Type I and II errors matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, title):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2b47d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = lr.predict(x_test_scaled)\n",
    "plot_confusion_matrix(y_test, y_pred, f'Confusion Matrix - Logistic Regression') #number of FN> number of FP: regarding satisfaction level we want more to avoid FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a16556f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "satisfaction                              1.000000\n",
       "online_boarding                           0.550152\n",
       "class                                     0.492967\n",
       "type_of_travel                            0.449314\n",
       "in_flight_entertainment                   0.400665\n",
       "seat_comfort                              0.363986\n",
       "on_board_service                          0.328122\n",
       "leg_room_service                          0.317202\n",
       "cleanliness                               0.306456\n",
       "in_flight_wifi_service                    0.286471\n",
       "baggage_handling                          0.271190\n",
       "in_flight_service                         0.265880\n",
       "flight_distance_log                       0.255021\n",
       "check_in_service                          0.236024\n",
       "food_and_drink                            0.209802\n",
       "customer_type                             0.189022\n",
       "ease_of_online_booking                    0.173773\n",
       "age_zscore                                0.145128\n",
       "arrival_delay_cut                         0.100194\n",
       "departure_delay_cut                       0.068896\n",
       "departure_and_arrival_time_convenience    0.050276\n",
       "gender                                    0.012514\n",
       "gate_location                             0.001643\n",
       "Name: satisfaction, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Feature selection for model based on correlation\n",
    "feature_selection_with_corr = (df_train.corr(method=\"spearman\")[\"satisfaction\"]\n",
    "  .apply(np.abs)\n",
    "  .sort_values(ascending=False)\n",
    " )\n",
    "\n",
    "feature_selection_with_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "070cfc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wrapper for Modelling and scoring\n",
    "def logit_model_wrapper(\n",
    "    X_train: pd.DataFrame,\n",
    "    y_train: pd.DataFrame,\n",
    "    X_test: pd.DataFrame,\n",
    "    fit_intercept: bool=True,\n",
    ") -> np.array :\n",
    "    reg = LogisticRegression(fit_intercept=fit_intercept)\n",
    "    reg.fit(X=X_train, y=y_train)\n",
    "    pred = reg.predict(X_test)\n",
    "    return pred.ravel()  \n",
    "\n",
    "\n",
    "def scoring_wrapper(y_true: np.array, y_pred: np.array) -> dict:\n",
    "    accuracy = metrics.accuracy_score(y_true, y_pred)\n",
    "    precision = metrics.precision_score(y_true, y_pred)\n",
    "    recall = metrics.recall_score(y_true, y_pred)\n",
    "    fbeta_precision = metrics.fbeta_score(y_true, y_pred, beta=0.25) #more emphasis on precision\n",
    "    fbeta_recall = metrics.fbeta_score(y_true, y_pred, beta=0.75) #more emphasis on recall\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"fbeta_precision\": fbeta_precision, \"fbeta_recall\": fbeta_recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e04e0fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/22 [00:00<?, ?it/s]C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "  5%|███▊                                                                               | 1/22 [00:00<00:05,  3.88it/s]C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "  9%|███████▌                                                                           | 2/22 [00:00<00:05,  3.66it/s]C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      " 14%|███████████▎                                                                       | 3/22 [00:00<00:05,  3.52it/s]C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      " 18%|███████████████                                                                    | 4/22 [00:01<00:06,  3.00it/s]C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      " 23%|██████████████████▊                                                                | 5/22 [00:01<00:05,  2.94it/s]C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      " 27%|██████████████████████▋                                                            | 6/22 [00:01<00:05,  2.84it/s]C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      " 32%|██████████████████████████▍                                                        | 7/22 [00:02<00:05,  2.64it/s]C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      " 36%|██████████████████████████████▏                                                    | 8/22 [00:02<00:06,  2.25it/s]C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      " 41%|█████████████████████████████████▉                                                 | 9/22 [00:03<00:07,  1.84it/s]C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      " 45%|█████████████████████████████████████▎                                            | 10/22 [00:04<00:08,  1.47it/s]C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      " 50%|█████████████████████████████████████████                                         | 11/22 [00:05<00:06,  1.62it/s]C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      " 55%|████████████████████████████████████████████▋                                     | 12/22 [00:06<00:06,  1.46it/s]C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      " 59%|████████████████████████████████████████████████▍                                 | 13/22 [00:07<00:07,  1.24it/s]C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      " 64%|████████████████████████████████████████████████████▏                             | 14/22 [00:08<00:07,  1.12it/s]C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      " 68%|███████████████████████████████████████████████████████▉                          | 15/22 [00:09<00:06,  1.04it/s]C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      " 73%|███████████████████████████████████████████████████████████▋                      | 16/22 [00:10<00:06,  1.02s/it]C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      " 77%|███████████████████████████████████████████████████████████████▎                  | 17/22 [00:11<00:05,  1.00s/it]C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      " 82%|███████████████████████████████████████████████████████████████████               | 18/22 [00:12<00:04,  1.06s/it]C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|██████████████████████████████████████████████████████████████████████▊           | 19/22 [00:14<00:03,  1.15s/it]C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      " 91%|██████████████████████████████████████████████████████████████████████████▌       | 20/22 [00:15<00:02,  1.21s/it]C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      " 95%|██████████████████████████████████████████████████████████████████████████████▎   | 21/22 [00:16<00:01,  1.24s/it]C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:18<00:00,  1.22it/s]\n"
     ]
    }
   ],
   "source": [
    "#Let's create some models (from containing least variables to all variables ~econometric GETS)\n",
    "scores_on_train = dict()\n",
    "\n",
    "for i in tqdm(range(1, 23)):\n",
    "    feautres_i = feature_selection_with_corr.index[1 : 1 + i]\n",
    "    pred = logit_model_wrapper(\n",
    "        df_train[feautres_i], df_train[[\"satisfaction\"]], df_train[feautres_i]\n",
    "    )\n",
    "    score = scoring_wrapper(df_train[[\"satisfaction\"]].to_numpy().ravel(), pred)\n",
    "    scores_on_train.update({f\"top_{i}\": score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5e0ba69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'top_1': {'accuracy': 0.787091931013243,\n",
       "  'precision': 0.7227130070905498,\n",
       "  'recall': 0.8269051735603139,\n",
       "  'fbeta_precision': 0.7281096943520221,\n",
       "  'fbeta_recall': 0.7570536579663839},\n",
       " 'top_2': {'accuracy': 0.7888820449645827,\n",
       "  'precision': 0.7358555845001629,\n",
       "  'recall': 0.80145852728643,\n",
       "  'fbeta_precision': 0.7394158476584586,\n",
       "  'fbeta_recall': 0.7581978557325018},\n",
       " 'top_3': {'accuracy': 0.8126443640283338,\n",
       "  'precision': 0.7630623422979875,\n",
       "  'recall': 0.8245112381965687,\n",
       "  'fbeta_precision': 0.76642232257783,\n",
       "  'fbeta_recall': 0.7840997050535506},\n",
       " 'top_4': {'accuracy': 0.8350977825685247,\n",
       "  'precision': 0.8114009704847972,\n",
       "  'recall': 0.8080196834685464,\n",
       "  'fbeta_precision': 0.8112012880761327,\n",
       "  'fbeta_recall': 0.8101804520101489},\n",
       " 'top_5': {'accuracy': 0.8351074068370804,\n",
       "  'precision': 0.8113913062832468,\n",
       "  'recall': 0.808064015604912,\n",
       "  'fbeta_precision': 0.8111948249818711,\n",
       "  'fbeta_recall': 0.8101903297211281},\n",
       " 'top_6': {'accuracy': 0.8416230366492147,\n",
       "  'precision': 0.8204015920576003,\n",
       "  'recall': 0.8132730416278761,\n",
       "  'fbeta_precision': 0.8199788080445295,\n",
       "  'fbeta_recall': 0.8178209629646801},\n",
       " 'top_7': {'accuracy': 0.8531914074530336,\n",
       "  'precision': 0.8471608612751709,\n",
       "  'recall': 0.8075763621048898,\n",
       "  'fbeta_precision': 0.8447252492464642,\n",
       "  'fbeta_recall': 0.8324711503835953},\n",
       " 'top_8': {'accuracy': 0.8530662919618109,\n",
       "  'precision': 0.8445024123363882,\n",
       "  'recall': 0.8109012723323137,\n",
       "  'fbeta_precision': 0.84244897848603,\n",
       "  'fbeta_recall': 0.8320899256684833},\n",
       " 'top_9': {'accuracy': 0.8545484293193717,\n",
       "  'precision': 0.8433315785859788,\n",
       "  'recall': 0.8167309482643968,\n",
       "  'fbeta_precision': 0.8417189620651195,\n",
       "  'fbeta_recall': 0.8335580527055911},\n",
       " 'top_10': {'accuracy': 0.8553953649522636,\n",
       "  'precision': 0.8450335986056006,\n",
       "  'recall': 0.8167309482643968,\n",
       "  'fbeta_precision': 0.8433145475939802,\n",
       "  'fbeta_recall': 0.8346214552485606},\n",
       " 'top_11': {'accuracy': 0.8547409146904835,\n",
       "  'precision': 0.8437650291995877,\n",
       "  'recall': 0.8166644500598483,\n",
       "  'fbeta_precision': 0.8421211852306004,\n",
       "  'fbeta_recall': 0.8338040638527843},\n",
       " 'top_12': {'accuracy': 0.8547216661533723,\n",
       "  'precision': 0.8441993257963171,\n",
       "  'recall': 0.8159994680143636,\n",
       "  'fbeta_precision': 0.8424866657871426,\n",
       "  'fbeta_recall': 0.833825599915922},\n",
       " 'top_13': {'accuracy': 0.8569544964582692,\n",
       "  'precision': 0.8463035464889987,\n",
       "  'recall': 0.8193465443099703,\n",
       "  'fbeta_precision': 0.8446688334906027,\n",
       "  'fbeta_recall': 0.8363970754612811},\n",
       " 'top_14': {'accuracy': 0.8571373575608254,\n",
       "  'precision': 0.8465448550625085,\n",
       "  'recall': 0.8195238728554329,\n",
       "  'fbeta_precision': 0.844906156489196,\n",
       "  'fbeta_recall': 0.8366144404920303},\n",
       " 'top_15': {'accuracy': 0.8712850323375424,\n",
       "  'precision': 0.8651633686148182,\n",
       "  'recall': 0.8334441636742475,\n",
       "  'fbeta_precision': 0.8632308494288793,\n",
       "  'fbeta_recall': 0.8534700822418297},\n",
       " 'top_16': {'accuracy': 0.8723629504157684,\n",
       "  'precision': 0.8669078007648712,\n",
       "  'recall': 0.8340869796515494,\n",
       "  'fbeta_precision': 0.8649058287475831,\n",
       "  'fbeta_recall': 0.854798904519855},\n",
       " 'top_17': {'accuracy': 0.8722474591931013,\n",
       "  'precision': 0.8669893960350392,\n",
       "  'recall': 0.8336658243560757,\n",
       "  'fbeta_precision': 0.8649556138172118,\n",
       "  'fbeta_recall': 0.8546903662010751},\n",
       " 'top_18': {'accuracy': 0.8638839698182939,\n",
       "  'precision': 0.8537198200050252,\n",
       "  'recall': 0.8284567983331117,\n",
       "  'fbeta_precision': 0.8521911858987256,\n",
       "  'fbeta_recall': 0.844449565743929},\n",
       " 'top_19': {'accuracy': 0.8463870495842316,\n",
       "  'precision': 0.8221397157948241,\n",
       "  'recall': 0.8245999024693,\n",
       "  'fbeta_precision': 0.8222840262229261,\n",
       "  'fbeta_recall': 0.8230236900558403},\n",
       " 'top_20': {'accuracy': 0.8493994456421312,\n",
       "  'precision': 0.8251600088280733,\n",
       "  'recall': 0.8287449572194884,\n",
       "  'fbeta_precision': 0.8253700293738004,\n",
       "  'fbeta_recall': 0.8264470117225148},\n",
       " 'top_21': {'accuracy': 0.8479558053587928,\n",
       "  'precision': 0.8249246320269551,\n",
       "  'recall': 0.8248880613556767,\n",
       "  'fbeta_precision': 0.8249224807212358,\n",
       "  'fbeta_recall': 0.8249114662117468},\n",
       " 'top_22': {'accuracy': 0.8489952263627965,\n",
       "  'precision': 0.825573161016199,\n",
       "  'recall': 0.8269273396284967,\n",
       "  'fbeta_precision': 0.82565269579572,\n",
       "  'fbeta_recall': 0.8260601540786194}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_on_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0fec88a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>fbeta_precision</th>\n",
       "      <th>fbeta_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>top_1</th>\n",
       "      <td>0.787092</td>\n",
       "      <td>0.722713</td>\n",
       "      <td>0.826905</td>\n",
       "      <td>0.728110</td>\n",
       "      <td>0.757054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_2</th>\n",
       "      <td>0.788882</td>\n",
       "      <td>0.735856</td>\n",
       "      <td>0.801459</td>\n",
       "      <td>0.739416</td>\n",
       "      <td>0.758198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_3</th>\n",
       "      <td>0.812644</td>\n",
       "      <td>0.763062</td>\n",
       "      <td>0.824511</td>\n",
       "      <td>0.766422</td>\n",
       "      <td>0.784100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_5</th>\n",
       "      <td>0.835107</td>\n",
       "      <td>0.811391</td>\n",
       "      <td>0.808064</td>\n",
       "      <td>0.811195</td>\n",
       "      <td>0.810190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_4</th>\n",
       "      <td>0.835098</td>\n",
       "      <td>0.811401</td>\n",
       "      <td>0.808020</td>\n",
       "      <td>0.811201</td>\n",
       "      <td>0.810180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_6</th>\n",
       "      <td>0.841623</td>\n",
       "      <td>0.820402</td>\n",
       "      <td>0.813273</td>\n",
       "      <td>0.819979</td>\n",
       "      <td>0.817821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_19</th>\n",
       "      <td>0.846387</td>\n",
       "      <td>0.822140</td>\n",
       "      <td>0.824600</td>\n",
       "      <td>0.822284</td>\n",
       "      <td>0.823024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_21</th>\n",
       "      <td>0.847956</td>\n",
       "      <td>0.824925</td>\n",
       "      <td>0.824888</td>\n",
       "      <td>0.824922</td>\n",
       "      <td>0.824911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_20</th>\n",
       "      <td>0.849399</td>\n",
       "      <td>0.825160</td>\n",
       "      <td>0.828745</td>\n",
       "      <td>0.825370</td>\n",
       "      <td>0.826447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_22</th>\n",
       "      <td>0.848995</td>\n",
       "      <td>0.825573</td>\n",
       "      <td>0.826927</td>\n",
       "      <td>0.825653</td>\n",
       "      <td>0.826060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_9</th>\n",
       "      <td>0.854548</td>\n",
       "      <td>0.843332</td>\n",
       "      <td>0.816731</td>\n",
       "      <td>0.841719</td>\n",
       "      <td>0.833558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_11</th>\n",
       "      <td>0.854741</td>\n",
       "      <td>0.843765</td>\n",
       "      <td>0.816664</td>\n",
       "      <td>0.842121</td>\n",
       "      <td>0.833804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_12</th>\n",
       "      <td>0.854722</td>\n",
       "      <td>0.844199</td>\n",
       "      <td>0.815999</td>\n",
       "      <td>0.842487</td>\n",
       "      <td>0.833826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_8</th>\n",
       "      <td>0.853066</td>\n",
       "      <td>0.844502</td>\n",
       "      <td>0.810901</td>\n",
       "      <td>0.842449</td>\n",
       "      <td>0.832090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_10</th>\n",
       "      <td>0.855395</td>\n",
       "      <td>0.845034</td>\n",
       "      <td>0.816731</td>\n",
       "      <td>0.843315</td>\n",
       "      <td>0.834621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_13</th>\n",
       "      <td>0.856954</td>\n",
       "      <td>0.846304</td>\n",
       "      <td>0.819347</td>\n",
       "      <td>0.844669</td>\n",
       "      <td>0.836397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_14</th>\n",
       "      <td>0.857137</td>\n",
       "      <td>0.846545</td>\n",
       "      <td>0.819524</td>\n",
       "      <td>0.844906</td>\n",
       "      <td>0.836614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_7</th>\n",
       "      <td>0.853191</td>\n",
       "      <td>0.847161</td>\n",
       "      <td>0.807576</td>\n",
       "      <td>0.844725</td>\n",
       "      <td>0.832471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_18</th>\n",
       "      <td>0.863884</td>\n",
       "      <td>0.853720</td>\n",
       "      <td>0.828457</td>\n",
       "      <td>0.852191</td>\n",
       "      <td>0.844450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_15</th>\n",
       "      <td>0.871285</td>\n",
       "      <td>0.865163</td>\n",
       "      <td>0.833444</td>\n",
       "      <td>0.863231</td>\n",
       "      <td>0.853470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_16</th>\n",
       "      <td>0.872363</td>\n",
       "      <td>0.866908</td>\n",
       "      <td>0.834087</td>\n",
       "      <td>0.864906</td>\n",
       "      <td>0.854799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_17</th>\n",
       "      <td>0.872247</td>\n",
       "      <td>0.866989</td>\n",
       "      <td>0.833666</td>\n",
       "      <td>0.864956</td>\n",
       "      <td>0.854690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        accuracy  precision    recall  fbeta_precision  fbeta_recall\n",
       "top_1   0.787092   0.722713  0.826905         0.728110      0.757054\n",
       "top_2   0.788882   0.735856  0.801459         0.739416      0.758198\n",
       "top_3   0.812644   0.763062  0.824511         0.766422      0.784100\n",
       "top_5   0.835107   0.811391  0.808064         0.811195      0.810190\n",
       "top_4   0.835098   0.811401  0.808020         0.811201      0.810180\n",
       "top_6   0.841623   0.820402  0.813273         0.819979      0.817821\n",
       "top_19  0.846387   0.822140  0.824600         0.822284      0.823024\n",
       "top_21  0.847956   0.824925  0.824888         0.824922      0.824911\n",
       "top_20  0.849399   0.825160  0.828745         0.825370      0.826447\n",
       "top_22  0.848995   0.825573  0.826927         0.825653      0.826060\n",
       "top_9   0.854548   0.843332  0.816731         0.841719      0.833558\n",
       "top_11  0.854741   0.843765  0.816664         0.842121      0.833804\n",
       "top_12  0.854722   0.844199  0.815999         0.842487      0.833826\n",
       "top_8   0.853066   0.844502  0.810901         0.842449      0.832090\n",
       "top_10  0.855395   0.845034  0.816731         0.843315      0.834621\n",
       "top_13  0.856954   0.846304  0.819347         0.844669      0.836397\n",
       "top_14  0.857137   0.846545  0.819524         0.844906      0.836614\n",
       "top_7   0.853191   0.847161  0.807576         0.844725      0.832471\n",
       "top_18  0.863884   0.853720  0.828457         0.852191      0.844450\n",
       "top_15  0.871285   0.865163  0.833444         0.863231      0.853470\n",
       "top_16  0.872363   0.866908  0.834087         0.864906      0.854799\n",
       "top_17  0.872247   0.866989  0.833666         0.864956      0.854690"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Firstly let's sort by precision\n",
    "pd.DataFrame(scores_on_train).T.sort_values(\"precision\") #best precision for 17, not all 22 variables- some of them must be excluded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e769ccda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>fbeta_precision</th>\n",
       "      <th>fbeta_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>top_16</th>\n",
       "      <td>0.872363</td>\n",
       "      <td>0.866908</td>\n",
       "      <td>0.834087</td>\n",
       "      <td>0.864906</td>\n",
       "      <td>0.854799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        accuracy  precision    recall  fbeta_precision  fbeta_recall\n",
       "top_16  0.872363   0.866908  0.834087         0.864906      0.854799"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>fbeta_precision</th>\n",
       "      <th>fbeta_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>top_17</th>\n",
       "      <td>0.872247</td>\n",
       "      <td>0.866989</td>\n",
       "      <td>0.833666</td>\n",
       "      <td>0.864956</td>\n",
       "      <td>0.85469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        accuracy  precision    recall  fbeta_precision  fbeta_recall\n",
       "top_17  0.872247   0.866989  0.833666         0.864956       0.85469"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>fbeta_precision</th>\n",
       "      <th>fbeta_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>top_16</th>\n",
       "      <td>0.872363</td>\n",
       "      <td>0.866908</td>\n",
       "      <td>0.834087</td>\n",
       "      <td>0.864906</td>\n",
       "      <td>0.854799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        accuracy  precision    recall  fbeta_precision  fbeta_recall\n",
       "top_16  0.872363   0.866908  0.834087         0.864906      0.854799"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#How about comparing to other metrics?\n",
    "display(pd.DataFrame(scores_on_train).T.sort_values(\"recall\").tail(1)) #1 variable more to drop\n",
    "display(pd.DataFrame(scores_on_train).T.sort_values(\"fbeta_precision\").tail(1))\n",
    "display(pd.DataFrame(scores_on_train).T.sort_values(\"fbeta_recall\").tail(1)) #1 variable more to drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa338e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/22 [00:00<?, ?it/s]C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "  5%|███▊                                                                               | 1/22 [00:00<00:02,  9.01it/s]C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "  9%|███████▌                                                                           | 2/22 [00:00<00:02,  7.77it/s]C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      " 14%|███████████▎                                                                       | 3/22 [00:00<00:02,  6.48it/s]C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      " 18%|███████████████                                                                    | 4/22 [00:00<00:03,  5.70it/s]C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      " 23%|██████████████████▊                                                                | 5/22 [00:00<00:03,  4.56it/s]C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      " 27%|██████████████████████▋                                                            | 6/22 [00:01<00:03,  4.33it/s]C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      " 32%|██████████████████████████▍                                                        | 7/22 [00:01<00:03,  4.04it/s]C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      " 36%|██████████████████████████████▏                                                    | 8/22 [00:01<00:03,  3.65it/s]C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      " 41%|█████████████████████████████████▉                                                 | 9/22 [00:02<00:03,  3.41it/s]C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      " 45%|█████████████████████████████████████▎                                            | 10/22 [00:02<00:04,  2.80it/s]C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      " 50%|█████████████████████████████████████████                                         | 11/22 [00:02<00:03,  2.87it/s]C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      " 55%|████████████████████████████████████████████▋                                     | 12/22 [00:03<00:05,  1.97it/s]C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      " 59%|████████████████████████████████████████████████▍                                 | 13/22 [00:04<00:05,  1.68it/s]C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      " 64%|████████████████████████████████████████████████████▏                             | 14/22 [00:05<00:05,  1.46it/s]C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      " 68%|███████████████████████████████████████████████████████▉                          | 15/22 [00:06<00:05,  1.32it/s]C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      " 73%|███████████████████████████████████████████████████████████▋                      | 16/22 [00:07<00:05,  1.14it/s]C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      " 77%|███████████████████████████████████████████████████████████████▎                  | 17/22 [00:08<00:04,  1.13it/s]C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      " 82%|███████████████████████████████████████████████████████████████████               | 18/22 [00:09<00:03,  1.02it/s]C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|██████████████████████████████████████████████████████████████████████▊           | 19/22 [00:10<00:03,  1.01s/it]C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      " 91%|██████████████████████████████████████████████████████████████████████████▌       | 20/22 [00:11<00:02,  1.04s/it]C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      " 95%|██████████████████████████████████████████████████████████████████████████████▎   | 21/22 [00:12<00:01,  1.02s/it]C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:13<00:00,  1.58it/s]\n"
     ]
    }
   ],
   "source": [
    "#Now let's assess the metrics on test set\n",
    "scores_on_test = dict()\n",
    "\n",
    "for i in tqdm(range(1, 23)):\n",
    "    feautres_i = feature_selection_with_corr.index[1 : 1 + i]\n",
    "    pred = logit_model_wrapper(\n",
    "        df_train[feautres_i], df_train[[\"satisfaction\"]], df_test[feautres_i]\n",
    "    )\n",
    "    score = scoring_wrapper(df_test[[\"satisfaction\"]].to_numpy().ravel(), pred)\n",
    "    scores_on_test.update({f\"top_{i}\": score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e879b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'top_1': {'accuracy': 0.7860332614721282,\n",
       "  'precision': 0.7236208236208236,\n",
       "  'recall': 0.8231394732190207,\n",
       "  'fbeta_precision': 0.7288039625472992,\n",
       "  'fbeta_recall': 0.7565492321589883},\n",
       " 'top_2': {'accuracy': 0.7893825069294733,\n",
       "  'precision': 0.7404724668697013,\n",
       "  'recall': 0.7951210889163868,\n",
       "  'fbeta_precision': 0.7434783031434433,\n",
       "  'fbeta_recall': 0.759258634077175},\n",
       " 'top_3': {'accuracy': 0.8149060671388975,\n",
       "  'precision': 0.7681338608638312,\n",
       "  'recall': 0.8236697896411526,\n",
       "  'fbeta_precision': 0.7711925462210236,\n",
       "  'fbeta_recall': 0.7872425981117667},\n",
       " 'top_4': {'accuracy': 0.8356944872189713,\n",
       "  'precision': 0.8156244400645045,\n",
       "  'recall': 0.8046667845147605,\n",
       "  'fbeta_precision': 0.8149716175370971,\n",
       "  'fbeta_recall': 0.8116454721166259},\n",
       " 'top_5': {'accuracy': 0.8356944872189713,\n",
       "  'precision': 0.8156244400645045,\n",
       "  'recall': 0.8046667845147605,\n",
       "  'fbeta_precision': 0.8149716175370971,\n",
       "  'fbeta_recall': 0.8116454721166259},\n",
       " 'top_6': {'accuracy': 0.8427394518016631,\n",
       "  'precision': 0.8249572956936079,\n",
       "  'recall': 0.8110305815803429,\n",
       "  'fbeta_precision': 0.8241248507517884,\n",
       "  'fbeta_recall': 0.8198889182755885},\n",
       " 'top_7': {'accuracy': 0.853018170619033,\n",
       "  'precision': 0.8498879761015683,\n",
       "  'recall': 0.8046667845147605,\n",
       "  'fbeta_precision': 0.8470876709029808,\n",
       "  'fbeta_recall': 0.8330344267215191},\n",
       " 'top_8': {'accuracy': 0.8517477671696951,\n",
       "  'precision': 0.8457974237790752,\n",
       "  'recall': 0.8066996641329327,\n",
       "  'fbeta_precision': 0.8433929445018209,\n",
       "  'fbeta_recall': 0.8312931266895462},\n",
       " 'top_9': {'accuracy': 0.8549815214043732,\n",
       "  'precision': 0.8466060439055755,\n",
       "  'recall': 0.8146544104649107,\n",
       "  'fbeta_precision': 0.8446573156663396,\n",
       "  'fbeta_recall': 0.8348187437051207},\n",
       " 'top_10': {'accuracy': 0.8542500769941485,\n",
       "  'precision': 0.8462104488594555,\n",
       "  'recall': 0.8131518472688705,\n",
       "  'fbeta_precision': 0.8441915947880345,\n",
       "  'fbeta_recall': 0.8340041627686038},\n",
       " 'top_11': {'accuracy': 0.8539036033261472,\n",
       "  'precision': 0.845383555351401,\n",
       "  'recall': 0.813328619409581,\n",
       "  'fbeta_precision': 0.8434281893958183,\n",
       "  'fbeta_recall': 0.8335567746190023},\n",
       " 'top_12': {'accuracy': 0.8545195565137049,\n",
       "  'precision': 0.8471390398968027,\n",
       "  'recall': 0.8126215308467386,\n",
       "  'fbeta_precision': 0.8450276272964177,\n",
       "  'fbeta_recall': 0.8343800140848139},\n",
       " 'top_13': {'accuracy': 0.8571373575608254,\n",
       "  'precision': 0.850078276084354,\n",
       "  'recall': 0.8158918154498851,\n",
       "  'fbeta_precision': 0.8479881982945888,\n",
       "  'fbeta_recall': 0.8374460209747069},\n",
       " 'top_14': {'accuracy': 0.8579072990452725,\n",
       "  'precision': 0.8512579485761681,\n",
       "  'recall': 0.816422131872017,\n",
       "  'fbeta_precision': 0.8491266965878981,\n",
       "  'fbeta_recall': 0.8383797677914043},\n",
       " 'top_15': {'accuracy': 0.8705728364644287,\n",
       "  'precision': 0.8691736304549675,\n",
       "  'recall': 0.8273820045960757,\n",
       "  'fbeta_precision': 0.8665987780040734,\n",
       "  'fbeta_recall': 0.8536509742983666},\n",
       " 'top_16': {'accuracy': 0.8708808130582075,\n",
       "  'precision': 0.8694764203490531,\n",
       "  'recall': 0.8278239349478522,\n",
       "  'fbeta_precision': 0.8669105876972331,\n",
       "  'fbeta_recall': 0.8540072507641021},\n",
       " 'top_17': {'accuracy': 0.8722667077302125,\n",
       "  'precision': 0.8709408053442197,\n",
       "  'recall': 0.8296800424253138,\n",
       "  'fbeta_precision': 0.8684004309922617,\n",
       "  'fbeta_recall': 0.8556224797100709},\n",
       " 'top_18': {'accuracy': 0.8626039421004004,\n",
       "  'precision': 0.8560264778891239,\n",
       "  'recall': 0.82296270107831,\n",
       "  'fbeta_precision': 0.8540081792970985,\n",
       "  'fbeta_recall': 0.8438218213718653},\n",
       " 'top_19': {'accuracy': 0.8471666153372344,\n",
       "  'precision': 0.8273894436519258,\n",
       "  'recall': 0.8202227328972954,\n",
       "  'fbeta_precision': 0.8269644074015831,\n",
       "  'fbeta_recall': 0.824795045541485},\n",
       " 'top_20': {'accuracy': 0.8488219895287958,\n",
       "  'precision': 0.8280486721733724,\n",
       "  'recall': 0.8240233339225738,\n",
       "  'fbeta_precision': 0.8278107992353414,\n",
       "  'fbeta_recall': 0.8265950278398411},\n",
       " 'top_21': {'accuracy': 0.8487834924545734,\n",
       "  'precision': 0.8297321428571428,\n",
       "  'recall': 0.8213717518119145,\n",
       "  'fbeta_precision': 0.8292356467241252,\n",
       "  'fbeta_recall': 0.8267028673503518},\n",
       " 'top_22': {'accuracy': 0.848629504157684,\n",
       "  'precision': 0.8290247816009984,\n",
       "  'recall': 0.8219904543044017,\n",
       "  'fbeta_precision': 0.828607666586304,\n",
       "  'fbeta_recall': 0.826478596870401}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_on_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80a25230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>fbeta_precision</th>\n",
       "      <th>fbeta_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>top_1</th>\n",
       "      <td>0.786033</td>\n",
       "      <td>0.723621</td>\n",
       "      <td>0.823139</td>\n",
       "      <td>0.728804</td>\n",
       "      <td>0.756549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_2</th>\n",
       "      <td>0.789383</td>\n",
       "      <td>0.740472</td>\n",
       "      <td>0.795121</td>\n",
       "      <td>0.743478</td>\n",
       "      <td>0.759259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_3</th>\n",
       "      <td>0.814906</td>\n",
       "      <td>0.768134</td>\n",
       "      <td>0.823670</td>\n",
       "      <td>0.771193</td>\n",
       "      <td>0.787243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_4</th>\n",
       "      <td>0.835694</td>\n",
       "      <td>0.815624</td>\n",
       "      <td>0.804667</td>\n",
       "      <td>0.814972</td>\n",
       "      <td>0.811645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_5</th>\n",
       "      <td>0.835694</td>\n",
       "      <td>0.815624</td>\n",
       "      <td>0.804667</td>\n",
       "      <td>0.814972</td>\n",
       "      <td>0.811645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_6</th>\n",
       "      <td>0.842739</td>\n",
       "      <td>0.824957</td>\n",
       "      <td>0.811031</td>\n",
       "      <td>0.824125</td>\n",
       "      <td>0.819889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_19</th>\n",
       "      <td>0.847167</td>\n",
       "      <td>0.827389</td>\n",
       "      <td>0.820223</td>\n",
       "      <td>0.826964</td>\n",
       "      <td>0.824795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_20</th>\n",
       "      <td>0.848822</td>\n",
       "      <td>0.828049</td>\n",
       "      <td>0.824023</td>\n",
       "      <td>0.827811</td>\n",
       "      <td>0.826595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_22</th>\n",
       "      <td>0.848630</td>\n",
       "      <td>0.829025</td>\n",
       "      <td>0.821990</td>\n",
       "      <td>0.828608</td>\n",
       "      <td>0.826479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_21</th>\n",
       "      <td>0.848783</td>\n",
       "      <td>0.829732</td>\n",
       "      <td>0.821372</td>\n",
       "      <td>0.829236</td>\n",
       "      <td>0.826703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_11</th>\n",
       "      <td>0.853904</td>\n",
       "      <td>0.845384</td>\n",
       "      <td>0.813329</td>\n",
       "      <td>0.843428</td>\n",
       "      <td>0.833557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_8</th>\n",
       "      <td>0.851748</td>\n",
       "      <td>0.845797</td>\n",
       "      <td>0.806700</td>\n",
       "      <td>0.843393</td>\n",
       "      <td>0.831293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_10</th>\n",
       "      <td>0.854250</td>\n",
       "      <td>0.846210</td>\n",
       "      <td>0.813152</td>\n",
       "      <td>0.844192</td>\n",
       "      <td>0.834004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_9</th>\n",
       "      <td>0.854982</td>\n",
       "      <td>0.846606</td>\n",
       "      <td>0.814654</td>\n",
       "      <td>0.844657</td>\n",
       "      <td>0.834819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_12</th>\n",
       "      <td>0.854520</td>\n",
       "      <td>0.847139</td>\n",
       "      <td>0.812622</td>\n",
       "      <td>0.845028</td>\n",
       "      <td>0.834380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_7</th>\n",
       "      <td>0.853018</td>\n",
       "      <td>0.849888</td>\n",
       "      <td>0.804667</td>\n",
       "      <td>0.847088</td>\n",
       "      <td>0.833034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_13</th>\n",
       "      <td>0.857137</td>\n",
       "      <td>0.850078</td>\n",
       "      <td>0.815892</td>\n",
       "      <td>0.847988</td>\n",
       "      <td>0.837446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_14</th>\n",
       "      <td>0.857907</td>\n",
       "      <td>0.851258</td>\n",
       "      <td>0.816422</td>\n",
       "      <td>0.849127</td>\n",
       "      <td>0.838380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_18</th>\n",
       "      <td>0.862604</td>\n",
       "      <td>0.856026</td>\n",
       "      <td>0.822963</td>\n",
       "      <td>0.854008</td>\n",
       "      <td>0.843822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_15</th>\n",
       "      <td>0.870573</td>\n",
       "      <td>0.869174</td>\n",
       "      <td>0.827382</td>\n",
       "      <td>0.866599</td>\n",
       "      <td>0.853651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_16</th>\n",
       "      <td>0.870881</td>\n",
       "      <td>0.869476</td>\n",
       "      <td>0.827824</td>\n",
       "      <td>0.866911</td>\n",
       "      <td>0.854007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_17</th>\n",
       "      <td>0.872267</td>\n",
       "      <td>0.870941</td>\n",
       "      <td>0.829680</td>\n",
       "      <td>0.868400</td>\n",
       "      <td>0.855622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        accuracy  precision    recall  fbeta_precision  fbeta_recall\n",
       "top_1   0.786033   0.723621  0.823139         0.728804      0.756549\n",
       "top_2   0.789383   0.740472  0.795121         0.743478      0.759259\n",
       "top_3   0.814906   0.768134  0.823670         0.771193      0.787243\n",
       "top_4   0.835694   0.815624  0.804667         0.814972      0.811645\n",
       "top_5   0.835694   0.815624  0.804667         0.814972      0.811645\n",
       "top_6   0.842739   0.824957  0.811031         0.824125      0.819889\n",
       "top_19  0.847167   0.827389  0.820223         0.826964      0.824795\n",
       "top_20  0.848822   0.828049  0.824023         0.827811      0.826595\n",
       "top_22  0.848630   0.829025  0.821990         0.828608      0.826479\n",
       "top_21  0.848783   0.829732  0.821372         0.829236      0.826703\n",
       "top_11  0.853904   0.845384  0.813329         0.843428      0.833557\n",
       "top_8   0.851748   0.845797  0.806700         0.843393      0.831293\n",
       "top_10  0.854250   0.846210  0.813152         0.844192      0.834004\n",
       "top_9   0.854982   0.846606  0.814654         0.844657      0.834819\n",
       "top_12  0.854520   0.847139  0.812622         0.845028      0.834380\n",
       "top_7   0.853018   0.849888  0.804667         0.847088      0.833034\n",
       "top_13  0.857137   0.850078  0.815892         0.847988      0.837446\n",
       "top_14  0.857907   0.851258  0.816422         0.849127      0.838380\n",
       "top_18  0.862604   0.856026  0.822963         0.854008      0.843822\n",
       "top_15  0.870573   0.869174  0.827382         0.866599      0.853651\n",
       "top_16  0.870881   0.869476  0.827824         0.866911      0.854007\n",
       "top_17  0.872267   0.870941  0.829680         0.868400      0.855622"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scores_on_test).T.sort_values(\"precision\") #similar results concerning maximization of precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf08b6b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>fbeta_precision</th>\n",
       "      <th>fbeta_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>top_17</th>\n",
       "      <td>0.872267</td>\n",
       "      <td>0.870941</td>\n",
       "      <td>0.82968</td>\n",
       "      <td>0.8684</td>\n",
       "      <td>0.855622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        accuracy  precision   recall  fbeta_precision  fbeta_recall\n",
       "top_17  0.872267   0.870941  0.82968           0.8684      0.855622"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>fbeta_precision</th>\n",
       "      <th>fbeta_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>top_17</th>\n",
       "      <td>0.872267</td>\n",
       "      <td>0.870941</td>\n",
       "      <td>0.82968</td>\n",
       "      <td>0.8684</td>\n",
       "      <td>0.855622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        accuracy  precision   recall  fbeta_precision  fbeta_recall\n",
       "top_17  0.872267   0.870941  0.82968           0.8684      0.855622"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>fbeta_precision</th>\n",
       "      <th>fbeta_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>top_17</th>\n",
       "      <td>0.872267</td>\n",
       "      <td>0.870941</td>\n",
       "      <td>0.82968</td>\n",
       "      <td>0.8684</td>\n",
       "      <td>0.855622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        accuracy  precision   recall  fbeta_precision  fbeta_recall\n",
       "top_17  0.872267   0.870941  0.82968           0.8684      0.855622"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#How about comparing to other metrics?\n",
    "display(pd.DataFrame(scores_on_test).T.sort_values(\"recall\").tail(1)) \n",
    "display(pd.DataFrame(scores_on_test).T.sort_values(\"fbeta_precision\").tail(1))\n",
    "display(pd.DataFrame(scores_on_test).T.sort_values(\"fbeta_recall\").tail(1)) \n",
    "#on test set we obtain actually best metric value for 17 variables- we will apply this assumption in our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6db46cc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Let's analyse the ROC curve for the logistic regression with all variables\n",
    "y_proba = lr.predict_proba(x_test_scaled)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test.Satisfaction, y_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='black', lw=1, linestyle='--')\n",
    "plt.xlabel('FP Rate')\n",
    "plt.ylabel('TP Rate')\n",
    "plt.title('ROC Curve for model with all variables')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec67dd1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Similarly for PR curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test.Satisfaction, y_proba)\n",
    "average_precision = average_precision_score(y_test.Satisfaction, y_proba)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, color='red', lw=2, label=f'PR curve (AP = {average_precision:.2f})')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall (PR) Curve for model with all variables')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3165a24",
   "metadata": {},
   "source": [
    "LOGISTIC REGRESSION- EVALUATION AND CROSS-VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58766f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "satisfaction                              1.000000\n",
       "online_boarding                           0.550152\n",
       "class                                     0.492967\n",
       "type_of_travel                            0.449314\n",
       "in_flight_entertainment                   0.400665\n",
       "seat_comfort                              0.363986\n",
       "on_board_service                          0.328122\n",
       "leg_room_service                          0.317202\n",
       "cleanliness                               0.306456\n",
       "in_flight_wifi_service                    0.286471\n",
       "baggage_handling                          0.271190\n",
       "in_flight_service                         0.265880\n",
       "flight_distance_log                       0.255021\n",
       "check_in_service                          0.236024\n",
       "food_and_drink                            0.209802\n",
       "customer_type                             0.189022\n",
       "ease_of_online_booking                    0.173773\n",
       "age_zscore                                0.145128\n",
       "arrival_delay_cut                         0.100194\n",
       "departure_delay_cut                       0.068896\n",
       "departure_and_arrival_time_convenience    0.050276\n",
       "gender                                    0.012514\n",
       "gate_location                             0.001643\n",
       "Name: satisfaction, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's select the features basing on correlation value (17 out of 22)\n",
    "feature_selection_with_corr = (df_train.corr(method=\"spearman\")[\"satisfaction\"]\n",
    "  .apply(np.abs)\n",
    "  .sort_values(ascending=False)\n",
    " )\n",
    "\n",
    "feature_selection_with_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e84b2443",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here are 17 variables that we will include in our model, basing their impact on correlation with target\n",
    "features = ['customer_type', 'type_of_travel', 'class', 'ease_of_online_booking',\n",
    "       'check_in_service', 'online_boarding',\n",
    "       'on_board_service', 'seat_comfort', 'leg_room_service', 'cleanliness',\n",
    "       'food_and_drink', 'in_flight_service', 'in_flight_wifi_service',\n",
    "       'in_flight_entertainment', 'baggage_handling', 'flight_distance_log', 'age_zscore']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98931c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Precision: 0.8663732343718535 Valid Recall: 0.8709602418042316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Precision: 0.8676321799207932 Valid Recall: 0.8684089867033471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Precision: 0.8678425504977845 Valid Recall: 0.86266589728794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Precision: 0.8664903403863845 Valid Recall: 0.8684912443465151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Precision: 0.866737801361172 Valid Recall: 0.8654810761513908\n",
      "avg Train Precision: 0.8670152213075975 avg Val Precision 0.867201489258685\n"
     ]
    }
   ],
   "source": [
    "#Standard K-Folds cross-validation\n",
    "train_prec_list = list()\n",
    "val_prec_list = list()\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=False, random_state=None)\n",
    "for train_index, val_index in kf.split(df_train.index.values):\n",
    "    reg = LogisticRegression(fit_intercept=True)\n",
    "    reg.fit(\n",
    "        X=df_train[features].iloc[train_index],\n",
    "        y=df_train[[\"satisfaction\"]].iloc[train_index],\n",
    "    )\n",
    "    pred_train = reg.predict(df_train[features].iloc[train_index]).ravel()\n",
    "    pred_val = reg.predict(df_train[features].iloc[val_index]).ravel()\n",
    "    train_prec = scoring_wrapper(\n",
    "        df_train[[\"satisfaction\"]].iloc[train_index], pred_train\n",
    "    ).get(\"precision\")\n",
    "    val_prec = scoring_wrapper(df_train[[\"satisfaction\"]].iloc[val_index], pred_val).get(\n",
    "        \"precision\"\n",
    "    )\n",
    "    train_prec_list.append(train_prec)\n",
    "    val_prec_list.append(val_prec)\n",
    "    print(\n",
    "        \"Train Precision:\",\n",
    "        train_prec,\n",
    "        \"Valid Recall:\",\n",
    "        val_prec,\n",
    "    )\n",
    "\n",
    "print(\n",
    "    \"avg Train Precision:\", np.mean(train_prec_list), \"avg Val Precision\", np.mean(val_prec_list)\n",
    ")\n",
    "#Average Precision is higher than the precision level for regression with 17 variables (=0.866989)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "025e60c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Precision: 0.867588781223634 Valid Recall: 0.8618836176676794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Precision: 0.86724049331963 Valid Recall: 0.8663822142375927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Precision: 0.8675637575291555 Valid Recall: 0.8645592985694509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Precision: 0.8668084779210128 Valid Recall: 0.8700616579127655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Precision: 0.8668114460909555 Valid Recall: 0.863204266172038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Precision: 0.8665694028513655 Valid Recall: 0.8726975985078107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Precision: 0.8663933376041 Valid Recall: 0.8725199543899658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Precision: 0.866724560686555 Valid Recall: 0.8667913063799954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Precision: 0.8674982108168899 Valid Recall: 0.8611176057984569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mbuda\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Precision: 0.8670690983817108 Valid Recall: 0.8713570127504554\n",
      "avg Train Precision: 0.867026756642501 avg Val Precision 0.867057453238621\n"
     ]
    }
   ],
   "source": [
    "#Change of K-Folds parameters\n",
    "train_prec_list = list()\n",
    "val_prec_list = list()\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=123)\n",
    "for train_index, val_index in kf.split(df_train.index.values):\n",
    "    reg = LogisticRegression(fit_intercept=True)\n",
    "    reg.fit(\n",
    "        X=df_train[features].iloc[train_index],\n",
    "        y=df_train[[\"satisfaction\"]].iloc[train_index],\n",
    "    )\n",
    "    pred_train = reg.predict(df_train[features].iloc[train_index]).ravel()\n",
    "    pred_val = reg.predict(df_train[features].iloc[val_index]).ravel()\n",
    "    train_prec = scoring_wrapper(\n",
    "        df_train[[\"satisfaction\"]].iloc[train_index], pred_train\n",
    "    ).get(\"precision\")\n",
    "    val_prec = scoring_wrapper(df_train[[\"satisfaction\"]].iloc[val_index], pred_val).get(\n",
    "        \"precision\"\n",
    "    )\n",
    "    train_prec_list.append(train_prec)\n",
    "    val_prec_list.append(val_prec)\n",
    "    print(\n",
    "        \"Train Precision:\",\n",
    "        train_prec,\n",
    "        \"Valid Recall:\",\n",
    "        val_prec,\n",
    "    )\n",
    "\n",
    "print(\n",
    "    \"avg Train Precision:\", np.mean(train_prec_list), \"avg Val Precision\", np.mean(val_prec_list)\n",
    ") #even higher train Precision, but drop in validation Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c8a75ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8681116 , 0.87316048, 0.86840302, 0.86461467, 0.86757255,\n",
       "       0.86040609, 0.87328528, 0.86558891, 0.86532295, 0.86554239])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's use scikit-learn ready-made function: cross_val_score\n",
    "reg = LogisticRegression(fit_intercept=True)\n",
    "scores = cross_val_score(estimator=reg,\n",
    "                         X=df_train[features],\n",
    "                         y=df_train[[\"satisfaction\"]],\n",
    "                         scoring=\"precision\", \n",
    "                         cv=10,\n",
    "                         n_jobs=-1\n",
    "                         )\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "62adb30f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8672007936723072"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statistics as s\n",
    "s.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a0fdcdec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.86440678, 0.87231121, 0.86711763, 0.86519692, 0.86739055,\n",
       "       0.86369383, 0.87288623, 0.86876282, 0.86716937, 0.86416916,\n",
       "       0.86116607, 0.87008923, 0.8721709 , 0.86644579, 0.8642596 ,\n",
       "       0.87349609, 0.86911542, 0.86925353, 0.86538908, 0.86708788])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using ShuffleSplit\n",
    "ss = ShuffleSplit(n_splits=20, test_size=0.2, random_state=123)\n",
    "reg = LogisticRegression(fit_intercept=True)\n",
    "scores = cross_val_score(estimator=reg,\n",
    "                         X=df_train[features],\n",
    "                         y=df_train[[\"satisfaction\"]],\n",
    "                         scoring=\"precision\", \n",
    "                         cv=ss,\n",
    "                         n_jobs=-1\n",
    "                         )\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d59c0577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8675789047370825"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eec4f1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([1.70960426, 1.68078423, 1.73506331, 1.35596657, 1.97477174,\n",
      "       1.65620422, 2.04995155, 1.88838935, 1.15879822, 1.08926129]), 'score_time': array([0.11427426, 0.10201216, 0.09702468, 0.11464453, 0.10495591,\n",
      "       0.10730028, 0.13382196, 0.10458565, 0.03598237, 0.02724624]), 'test_recall': array([0.83444149, 0.82845745, 0.84242021, 0.82801418, 0.83506983,\n",
      "       0.82664598, 0.83263135, 0.8308579 , 0.83750831, 0.84194192]), 'train_recall': array([0.83382592, 0.83439239, 0.83296389, 0.83387518, 0.83363298,\n",
      "       0.83466739, 0.83375613, 0.83437184, 0.83387927, 0.83326355]), 'test_precision': array([0.8681116 , 0.87316048, 0.86840302, 0.86461467, 0.86757255,\n",
      "       0.86040609, 0.87328528, 0.86558891, 0.86532295, 0.86554239]), 'train_precision': array([0.86700983, 0.86646717, 0.86689052, 0.86746093, 0.86709704,\n",
      "       0.86777283, 0.86635956, 0.8671547 , 0.86699785, 0.86684602]), 'test_brier': array([-0.09727761, -0.09766586, -0.09572402, -0.1002718 , -0.09626197,\n",
      "       -0.10162992, -0.0959574 , -0.10017531, -0.09636041, -0.09526225]), 'train_brier': array([-0.09765973, -0.09749854, -0.09792086, -0.0972178 , -0.0977931 ,\n",
      "       -0.097082  , -0.09781469, -0.0972717 , -0.09779421, -0.09791638]), 'test_roc': array([0.92566379, 0.92222185, 0.92977156, 0.92018099, 0.92669919,\n",
      "       0.91965085, 0.92647879, 0.9224376 , 0.92782169, 0.92923307]), 'train_roc': array([0.92504243, 0.9254909 , 0.92452733, 0.92566093, 0.92491248,\n",
      "       0.92574143, 0.92494205, 0.92543165, 0.92481176, 0.92466004])}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_brier</th>\n",
       "      <th>train_brier</th>\n",
       "      <th>test_roc</th>\n",
       "      <th>train_roc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.709604</td>\n",
       "      <td>0.114274</td>\n",
       "      <td>0.834441</td>\n",
       "      <td>0.833826</td>\n",
       "      <td>0.868112</td>\n",
       "      <td>0.867010</td>\n",
       "      <td>-0.097278</td>\n",
       "      <td>-0.097660</td>\n",
       "      <td>0.925664</td>\n",
       "      <td>0.925042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.680784</td>\n",
       "      <td>0.102012</td>\n",
       "      <td>0.828457</td>\n",
       "      <td>0.834392</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.866467</td>\n",
       "      <td>-0.097666</td>\n",
       "      <td>-0.097499</td>\n",
       "      <td>0.922222</td>\n",
       "      <td>0.925491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.735063</td>\n",
       "      <td>0.097025</td>\n",
       "      <td>0.842420</td>\n",
       "      <td>0.832964</td>\n",
       "      <td>0.868403</td>\n",
       "      <td>0.866891</td>\n",
       "      <td>-0.095724</td>\n",
       "      <td>-0.097921</td>\n",
       "      <td>0.929772</td>\n",
       "      <td>0.924527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.355967</td>\n",
       "      <td>0.114645</td>\n",
       "      <td>0.828014</td>\n",
       "      <td>0.833875</td>\n",
       "      <td>0.864615</td>\n",
       "      <td>0.867461</td>\n",
       "      <td>-0.100272</td>\n",
       "      <td>-0.097218</td>\n",
       "      <td>0.920181</td>\n",
       "      <td>0.925661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.974772</td>\n",
       "      <td>0.104956</td>\n",
       "      <td>0.835070</td>\n",
       "      <td>0.833633</td>\n",
       "      <td>0.867573</td>\n",
       "      <td>0.867097</td>\n",
       "      <td>-0.096262</td>\n",
       "      <td>-0.097793</td>\n",
       "      <td>0.926699</td>\n",
       "      <td>0.924912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.656204</td>\n",
       "      <td>0.107300</td>\n",
       "      <td>0.826646</td>\n",
       "      <td>0.834667</td>\n",
       "      <td>0.860406</td>\n",
       "      <td>0.867773</td>\n",
       "      <td>-0.101630</td>\n",
       "      <td>-0.097082</td>\n",
       "      <td>0.919651</td>\n",
       "      <td>0.925741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.049952</td>\n",
       "      <td>0.133822</td>\n",
       "      <td>0.832631</td>\n",
       "      <td>0.833756</td>\n",
       "      <td>0.873285</td>\n",
       "      <td>0.866360</td>\n",
       "      <td>-0.095957</td>\n",
       "      <td>-0.097815</td>\n",
       "      <td>0.926479</td>\n",
       "      <td>0.924942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.888389</td>\n",
       "      <td>0.104586</td>\n",
       "      <td>0.830858</td>\n",
       "      <td>0.834372</td>\n",
       "      <td>0.865589</td>\n",
       "      <td>0.867155</td>\n",
       "      <td>-0.100175</td>\n",
       "      <td>-0.097272</td>\n",
       "      <td>0.922438</td>\n",
       "      <td>0.925432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.158798</td>\n",
       "      <td>0.035982</td>\n",
       "      <td>0.837508</td>\n",
       "      <td>0.833879</td>\n",
       "      <td>0.865323</td>\n",
       "      <td>0.866998</td>\n",
       "      <td>-0.096360</td>\n",
       "      <td>-0.097794</td>\n",
       "      <td>0.927822</td>\n",
       "      <td>0.924812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.089261</td>\n",
       "      <td>0.027246</td>\n",
       "      <td>0.841942</td>\n",
       "      <td>0.833264</td>\n",
       "      <td>0.865542</td>\n",
       "      <td>0.866846</td>\n",
       "      <td>-0.095262</td>\n",
       "      <td>-0.097916</td>\n",
       "      <td>0.929233</td>\n",
       "      <td>0.924660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_recall  train_recall  test_precision  \\\n",
       "0  1.709604    0.114274     0.834441      0.833826        0.868112   \n",
       "1  1.680784    0.102012     0.828457      0.834392        0.873160   \n",
       "2  1.735063    0.097025     0.842420      0.832964        0.868403   \n",
       "3  1.355967    0.114645     0.828014      0.833875        0.864615   \n",
       "4  1.974772    0.104956     0.835070      0.833633        0.867573   \n",
       "5  1.656204    0.107300     0.826646      0.834667        0.860406   \n",
       "6  2.049952    0.133822     0.832631      0.833756        0.873285   \n",
       "7  1.888389    0.104586     0.830858      0.834372        0.865589   \n",
       "8  1.158798    0.035982     0.837508      0.833879        0.865323   \n",
       "9  1.089261    0.027246     0.841942      0.833264        0.865542   \n",
       "\n",
       "   train_precision  test_brier  train_brier  test_roc  train_roc  \n",
       "0         0.867010   -0.097278    -0.097660  0.925664   0.925042  \n",
       "1         0.866467   -0.097666    -0.097499  0.922222   0.925491  \n",
       "2         0.866891   -0.095724    -0.097921  0.929772   0.924527  \n",
       "3         0.867461   -0.100272    -0.097218  0.920181   0.925661  \n",
       "4         0.867097   -0.096262    -0.097793  0.926699   0.924912  \n",
       "5         0.867773   -0.101630    -0.097082  0.919651   0.925741  \n",
       "6         0.866360   -0.095957    -0.097815  0.926479   0.924942  \n",
       "7         0.867155   -0.100175    -0.097272  0.922438   0.925432  \n",
       "8         0.866998   -0.096360    -0.097794  0.927822   0.924812  \n",
       "9         0.866846   -0.095262    -0.097916  0.929233   0.924660  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Now let's use scikit-learn ready-made function: cross_validate, so as to access the model by different metrics\n",
    "scoring = {'recall': 'recall',\n",
    "           'precision': 'precision',\n",
    "           'brier': 'neg_brier_score',\n",
    "           'roc': 'roc_auc'\n",
    "          }\n",
    "reg = LogisticRegression(fit_intercept=True)\n",
    "scores = cross_validate(estimator=reg,\n",
    "                         X=df_train[features],\n",
    "                         y=df_train[[\"satisfaction\"]],\n",
    "                         scoring=scoring,\n",
    "                         cv=10,\n",
    "                         n_jobs=-1,\n",
    "                         return_train_score=True)\n",
    "sorted(scores.keys())\n",
    "print(scores)\n",
    "display(pd.DataFrame(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf11d09",
   "metadata": {},
   "source": [
    "LOGISTIC REGRESSION - REGULARIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f9cf2a",
   "metadata": {},
   "source": [
    "1) Lasso (L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5cd023b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(penalty=&#x27;l1&#x27;, random_state=123, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(penalty=&#x27;l1&#x27;, random_state=123, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(penalty='l1', random_state=123, solver='liblinear')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Basic Lasso regularisation\n",
    "lasso = LogisticRegression(penalty='l1', solver='liblinear', C=1.0, random_state=123) \n",
    "lasso.fit(x_train_scaled, y_train.Satisfaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "941cc40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.87430705\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89     14662\n",
      "           1       0.87      0.83      0.85     11314\n",
      "\n",
      "    accuracy                           0.87     25976\n",
      "   macro avg       0.87      0.87      0.87     25976\n",
      "weighted avg       0.87      0.87      0.87     25976\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_lasso = lasso.predict(x_test_scaled)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.8f}\") #drop in accuracy level\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bca4e8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Lasso Regularisation Accuracy: 0.65016120\n",
      "\n",
      "Logistic Regression Grid Search Results:\n",
      "Best parameters: [1.3912797]\n",
      "Best cross-validation accuracy: 0.87442705\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameter tuning \n",
    "lasso_alpha= np.logspace(-4, 0, 10)\n",
    "lasso_C = 1 / (2* lasso_alpha) #conversion for LogisticRegression, source: https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.Lasso.html\n",
    "lasso_grid_search = LogisticRegressionCV(Cs=lasso_C, random_state=123, penalty='l1', solver='liblinear', cv=10, scoring='accuracy')\n",
    "lasso_grid_search.fit(x_train_scaled, y_train.Satisfaction)\n",
    "lasso_grid_val_pred = lasso_grid_search.predict(x_val_scaled)\n",
    "\n",
    "print(f\"Tuned Lasso Regularisation Accuracy: {accuracy_score(y_val.Satisfaction, lasso_grid_val_pred):.8f}\") #slight drop in accuracy\n",
    "print(\"\\nLogistic Regression Grid Search Results:\")\n",
    "print(f\"Best parameters: {lasso_grid_search.C_}\") #high value of C = low value of alpha: insignificant impact of Lasso regularisation\n",
    "print(f\"Best cross-validation accuracy: {lasso_grid_search.score(x_train_scaled, y_train.Satisfaction):.8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "be4c3da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([42.1679821 , 43.19329333, 43.3089931 , 43.10344315, 41.44095135,\n",
      "       44.69942999, 41.87709427, 45.04897523, 10.720963  , 10.38407326]), 'score_time': array([0.16971874, 0.15462232, 0.17531347, 0.17538714, 0.18566966,\n",
      "       0.11481786, 0.18575573, 0.10553312, 0.03939986, 0.03172278]), 'test_recall': array([0.83444149, 0.82845745, 0.84242021, 0.82801418, 0.83551319,\n",
      "       0.82664598, 0.83307471, 0.83107958, 0.83750831, 0.84194192]), 'train_recall': array([0.83377666, 0.83446628, 0.83298852, 0.83382592, 0.83363298,\n",
      "       0.83469202, 0.83387927, 0.83444573, 0.83395316, 0.83336207]), 'test_precision': array([0.8681116 , 0.87336449, 0.86840302, 0.86461467, 0.86763352,\n",
      "       0.86060466, 0.87334418, 0.86581986, 0.86532295, 0.86534518]), 'train_precision': array([0.86695862, 0.86656606, 0.86678285, 0.86734302, 0.86705262,\n",
      "       0.86773178, 0.86633233, 0.86707614, 0.86698587, 0.86679304]), 'test_brier': array([-0.09728326, -0.09766807, -0.09572951, -0.10027305, -0.09626446,\n",
      "       -0.10163761, -0.09595981, -0.10018045, -0.09636348, -0.09526926]), 'train_brier': array([-0.09766389, -0.09750349, -0.09792502, -0.09722222, -0.09779709,\n",
      "       -0.09708539, -0.09781921, -0.09727583, -0.09779801, -0.09792095]), 'test_roc': array([0.92566262, 0.92223052, 0.92977563, 0.92018185, 0.92670047,\n",
      "       0.91965036, 0.92648312, 0.92243628, 0.92782184, 0.92923854]), 'train_roc': array([0.92504428, 0.92549293, 0.92452913, 0.92566314, 0.92491387,\n",
      "       0.92574385, 0.92494414, 0.92543362, 0.92481295, 0.92466436])}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_brier</th>\n",
       "      <th>train_brier</th>\n",
       "      <th>test_roc</th>\n",
       "      <th>train_roc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42.167982</td>\n",
       "      <td>0.169719</td>\n",
       "      <td>0.834441</td>\n",
       "      <td>0.833777</td>\n",
       "      <td>0.868112</td>\n",
       "      <td>0.866959</td>\n",
       "      <td>-0.097283</td>\n",
       "      <td>-0.097664</td>\n",
       "      <td>0.925663</td>\n",
       "      <td>0.925044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43.193293</td>\n",
       "      <td>0.154622</td>\n",
       "      <td>0.828457</td>\n",
       "      <td>0.834466</td>\n",
       "      <td>0.873364</td>\n",
       "      <td>0.866566</td>\n",
       "      <td>-0.097668</td>\n",
       "      <td>-0.097503</td>\n",
       "      <td>0.922231</td>\n",
       "      <td>0.925493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43.308993</td>\n",
       "      <td>0.175313</td>\n",
       "      <td>0.842420</td>\n",
       "      <td>0.832989</td>\n",
       "      <td>0.868403</td>\n",
       "      <td>0.866783</td>\n",
       "      <td>-0.095730</td>\n",
       "      <td>-0.097925</td>\n",
       "      <td>0.929776</td>\n",
       "      <td>0.924529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43.103443</td>\n",
       "      <td>0.175387</td>\n",
       "      <td>0.828014</td>\n",
       "      <td>0.833826</td>\n",
       "      <td>0.864615</td>\n",
       "      <td>0.867343</td>\n",
       "      <td>-0.100273</td>\n",
       "      <td>-0.097222</td>\n",
       "      <td>0.920182</td>\n",
       "      <td>0.925663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.440951</td>\n",
       "      <td>0.185670</td>\n",
       "      <td>0.835513</td>\n",
       "      <td>0.833633</td>\n",
       "      <td>0.867634</td>\n",
       "      <td>0.867053</td>\n",
       "      <td>-0.096264</td>\n",
       "      <td>-0.097797</td>\n",
       "      <td>0.926700</td>\n",
       "      <td>0.924914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>44.699430</td>\n",
       "      <td>0.114818</td>\n",
       "      <td>0.826646</td>\n",
       "      <td>0.834692</td>\n",
       "      <td>0.860605</td>\n",
       "      <td>0.867732</td>\n",
       "      <td>-0.101638</td>\n",
       "      <td>-0.097085</td>\n",
       "      <td>0.919650</td>\n",
       "      <td>0.925744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>41.877094</td>\n",
       "      <td>0.185756</td>\n",
       "      <td>0.833075</td>\n",
       "      <td>0.833879</td>\n",
       "      <td>0.873344</td>\n",
       "      <td>0.866332</td>\n",
       "      <td>-0.095960</td>\n",
       "      <td>-0.097819</td>\n",
       "      <td>0.926483</td>\n",
       "      <td>0.924944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>45.048975</td>\n",
       "      <td>0.105533</td>\n",
       "      <td>0.831080</td>\n",
       "      <td>0.834446</td>\n",
       "      <td>0.865820</td>\n",
       "      <td>0.867076</td>\n",
       "      <td>-0.100180</td>\n",
       "      <td>-0.097276</td>\n",
       "      <td>0.922436</td>\n",
       "      <td>0.925434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.720963</td>\n",
       "      <td>0.039400</td>\n",
       "      <td>0.837508</td>\n",
       "      <td>0.833953</td>\n",
       "      <td>0.865323</td>\n",
       "      <td>0.866986</td>\n",
       "      <td>-0.096363</td>\n",
       "      <td>-0.097798</td>\n",
       "      <td>0.927822</td>\n",
       "      <td>0.924813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.384073</td>\n",
       "      <td>0.031723</td>\n",
       "      <td>0.841942</td>\n",
       "      <td>0.833362</td>\n",
       "      <td>0.865345</td>\n",
       "      <td>0.866793</td>\n",
       "      <td>-0.095269</td>\n",
       "      <td>-0.097921</td>\n",
       "      <td>0.929239</td>\n",
       "      <td>0.924664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fit_time  score_time  test_recall  train_recall  test_precision  \\\n",
       "0  42.167982    0.169719     0.834441      0.833777        0.868112   \n",
       "1  43.193293    0.154622     0.828457      0.834466        0.873364   \n",
       "2  43.308993    0.175313     0.842420      0.832989        0.868403   \n",
       "3  43.103443    0.175387     0.828014      0.833826        0.864615   \n",
       "4  41.440951    0.185670     0.835513      0.833633        0.867634   \n",
       "5  44.699430    0.114818     0.826646      0.834692        0.860605   \n",
       "6  41.877094    0.185756     0.833075      0.833879        0.873344   \n",
       "7  45.048975    0.105533     0.831080      0.834446        0.865820   \n",
       "8  10.720963    0.039400     0.837508      0.833953        0.865323   \n",
       "9  10.384073    0.031723     0.841942      0.833362        0.865345   \n",
       "\n",
       "   train_precision  test_brier  train_brier  test_roc  train_roc  \n",
       "0         0.866959   -0.097283    -0.097664  0.925663   0.925044  \n",
       "1         0.866566   -0.097668    -0.097503  0.922231   0.925493  \n",
       "2         0.866783   -0.095730    -0.097925  0.929776   0.924529  \n",
       "3         0.867343   -0.100273    -0.097222  0.920182   0.925663  \n",
       "4         0.867053   -0.096264    -0.097797  0.926700   0.924914  \n",
       "5         0.867732   -0.101638    -0.097085  0.919650   0.925744  \n",
       "6         0.866332   -0.095960    -0.097819  0.926483   0.924944  \n",
       "7         0.867076   -0.100180    -0.097276  0.922436   0.925434  \n",
       "8         0.866986   -0.096363    -0.097798  0.927822   0.924813  \n",
       "9         0.866793   -0.095269    -0.097921  0.929239   0.924664  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Cross-validation\n",
    "scoring = {'recall': 'recall',\n",
    "           'precision': 'precision',\n",
    "           'brier': 'neg_brier_score',\n",
    "           'roc': 'roc_auc'\n",
    "          }\n",
    "scores = cross_validate(estimator=lasso,\n",
    "                         X=df_train[features],\n",
    "                         y=df_train[[\"satisfaction\"]],\n",
    "                         scoring=scoring,\n",
    "                         cv=10,\n",
    "                         n_jobs=-1,\n",
    "                         return_train_score=True)\n",
    "sorted(scores.keys())\n",
    "print(scores)\n",
    "display(pd.DataFrame(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f11514",
   "metadata": {},
   "source": [
    "2) Ridge (L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b8d64d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=123)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=123)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=123)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Basic Ridge regularisation\n",
    "ridge = LogisticRegression(penalty='l2', solver='lbfgs', C=1.0, random_state=123) \n",
    "ridge.fit(x_train_scaled, y_train.Satisfaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e396f37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.87430705\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89     14662\n",
      "           1       0.87      0.83      0.85     11314\n",
      "\n",
      "    accuracy                           0.87     25976\n",
      "   macro avg       0.87      0.87      0.87     25976\n",
      "weighted avg       0.87      0.87      0.87     25976\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_ridge = ridge.predict(x_test_scaled)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.8f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e0dd03aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Ridge Regularisation Accuracy: 0.65016120\n",
      "\n",
      "Logistic Regression Grid Search Results:\n",
      "Best parameters: [0.00215443]\n",
      "Best cross-validation accuracy: 0.87477593\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameter tuning \n",
    "ridge_alpha= np.logspace(-4, 0, 10)\n",
    "ridge_grid_search = LogisticRegressionCV(Cs=ridge_alpha, random_state=123, penalty='l2', solver='lbfgs', cv=10, scoring='accuracy')\n",
    "ridge_grid_search.fit(x_train_scaled, y_train.Satisfaction)\n",
    "ridge_grid_val_pred = ridge_grid_search.predict(x_val_scaled)\n",
    "\n",
    "print(f\"Tuned Ridge Regularisation Accuracy: {accuracy_score(y_val.Satisfaction, lasso_grid_val_pred):.8f}\")  #also drop in accuracy\n",
    "print(\"\\nLogistic Regression Grid Search Results:\")\n",
    "print(f\"Best parameters: {ridge_grid_search.C_}\") # low value of alpha- L2 isn't beneficial for our model\n",
    "print(f\"Best cross-validation accuracy: {ridge_grid_search.score(x_train_scaled, y_train.Satisfaction):.8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "78617086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([1.95081735, 1.77823758, 2.14096689, 1.97581553, 2.14640164,\n",
      "       1.92643309, 2.34145689, 2.19057369, 1.36344981, 1.4943459 ]), 'score_time': array([0.07950306, 0.08024454, 0.07737374, 0.07420206, 0.0679512 ,\n",
      "       0.08107853, 0.08541799, 0.09123993, 0.04161835, 0.03183317]), 'test_recall': array([0.83444149, 0.82845745, 0.84242021, 0.82801418, 0.83506983,\n",
      "       0.82664598, 0.83263135, 0.8308579 , 0.83750831, 0.84194192]), 'train_recall': array([0.83382592, 0.83439239, 0.83296389, 0.83387518, 0.83363298,\n",
      "       0.83466739, 0.83375613, 0.83437184, 0.83387927, 0.83326355]), 'test_precision': array([0.8681116 , 0.87316048, 0.86840302, 0.86461467, 0.86757255,\n",
      "       0.86040609, 0.87328528, 0.86558891, 0.86532295, 0.86554239]), 'train_precision': array([0.86700983, 0.86646717, 0.86689052, 0.86746093, 0.86709704,\n",
      "       0.86777283, 0.86635956, 0.8671547 , 0.86699785, 0.86684602]), 'test_brier': array([-0.09727761, -0.09766586, -0.09572402, -0.1002718 , -0.09626197,\n",
      "       -0.10162992, -0.0959574 , -0.10017531, -0.09636041, -0.09526225]), 'train_brier': array([-0.09765973, -0.09749854, -0.09792086, -0.0972178 , -0.0977931 ,\n",
      "       -0.097082  , -0.09781469, -0.0972717 , -0.09779421, -0.09791638]), 'test_roc': array([0.92566379, 0.92222185, 0.92977156, 0.92018099, 0.92669919,\n",
      "       0.91965085, 0.92647879, 0.9224376 , 0.92782169, 0.92923307]), 'train_roc': array([0.92504243, 0.9254909 , 0.92452733, 0.92566093, 0.92491248,\n",
      "       0.92574143, 0.92494205, 0.92543165, 0.92481176, 0.92466004])}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_brier</th>\n",
       "      <th>train_brier</th>\n",
       "      <th>test_roc</th>\n",
       "      <th>train_roc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.950817</td>\n",
       "      <td>0.079503</td>\n",
       "      <td>0.834441</td>\n",
       "      <td>0.833826</td>\n",
       "      <td>0.868112</td>\n",
       "      <td>0.867010</td>\n",
       "      <td>-0.097278</td>\n",
       "      <td>-0.097660</td>\n",
       "      <td>0.925664</td>\n",
       "      <td>0.925042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.778238</td>\n",
       "      <td>0.080245</td>\n",
       "      <td>0.828457</td>\n",
       "      <td>0.834392</td>\n",
       "      <td>0.873160</td>\n",
       "      <td>0.866467</td>\n",
       "      <td>-0.097666</td>\n",
       "      <td>-0.097499</td>\n",
       "      <td>0.922222</td>\n",
       "      <td>0.925491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.140967</td>\n",
       "      <td>0.077374</td>\n",
       "      <td>0.842420</td>\n",
       "      <td>0.832964</td>\n",
       "      <td>0.868403</td>\n",
       "      <td>0.866891</td>\n",
       "      <td>-0.095724</td>\n",
       "      <td>-0.097921</td>\n",
       "      <td>0.929772</td>\n",
       "      <td>0.924527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.975816</td>\n",
       "      <td>0.074202</td>\n",
       "      <td>0.828014</td>\n",
       "      <td>0.833875</td>\n",
       "      <td>0.864615</td>\n",
       "      <td>0.867461</td>\n",
       "      <td>-0.100272</td>\n",
       "      <td>-0.097218</td>\n",
       "      <td>0.920181</td>\n",
       "      <td>0.925661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.146402</td>\n",
       "      <td>0.067951</td>\n",
       "      <td>0.835070</td>\n",
       "      <td>0.833633</td>\n",
       "      <td>0.867573</td>\n",
       "      <td>0.867097</td>\n",
       "      <td>-0.096262</td>\n",
       "      <td>-0.097793</td>\n",
       "      <td>0.926699</td>\n",
       "      <td>0.924912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.926433</td>\n",
       "      <td>0.081079</td>\n",
       "      <td>0.826646</td>\n",
       "      <td>0.834667</td>\n",
       "      <td>0.860406</td>\n",
       "      <td>0.867773</td>\n",
       "      <td>-0.101630</td>\n",
       "      <td>-0.097082</td>\n",
       "      <td>0.919651</td>\n",
       "      <td>0.925741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.341457</td>\n",
       "      <td>0.085418</td>\n",
       "      <td>0.832631</td>\n",
       "      <td>0.833756</td>\n",
       "      <td>0.873285</td>\n",
       "      <td>0.866360</td>\n",
       "      <td>-0.095957</td>\n",
       "      <td>-0.097815</td>\n",
       "      <td>0.926479</td>\n",
       "      <td>0.924942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.190574</td>\n",
       "      <td>0.091240</td>\n",
       "      <td>0.830858</td>\n",
       "      <td>0.834372</td>\n",
       "      <td>0.865589</td>\n",
       "      <td>0.867155</td>\n",
       "      <td>-0.100175</td>\n",
       "      <td>-0.097272</td>\n",
       "      <td>0.922438</td>\n",
       "      <td>0.925432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.363450</td>\n",
       "      <td>0.041618</td>\n",
       "      <td>0.837508</td>\n",
       "      <td>0.833879</td>\n",
       "      <td>0.865323</td>\n",
       "      <td>0.866998</td>\n",
       "      <td>-0.096360</td>\n",
       "      <td>-0.097794</td>\n",
       "      <td>0.927822</td>\n",
       "      <td>0.924812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.494346</td>\n",
       "      <td>0.031833</td>\n",
       "      <td>0.841942</td>\n",
       "      <td>0.833264</td>\n",
       "      <td>0.865542</td>\n",
       "      <td>0.866846</td>\n",
       "      <td>-0.095262</td>\n",
       "      <td>-0.097916</td>\n",
       "      <td>0.929233</td>\n",
       "      <td>0.924660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_recall  train_recall  test_precision  \\\n",
       "0  1.950817    0.079503     0.834441      0.833826        0.868112   \n",
       "1  1.778238    0.080245     0.828457      0.834392        0.873160   \n",
       "2  2.140967    0.077374     0.842420      0.832964        0.868403   \n",
       "3  1.975816    0.074202     0.828014      0.833875        0.864615   \n",
       "4  2.146402    0.067951     0.835070      0.833633        0.867573   \n",
       "5  1.926433    0.081079     0.826646      0.834667        0.860406   \n",
       "6  2.341457    0.085418     0.832631      0.833756        0.873285   \n",
       "7  2.190574    0.091240     0.830858      0.834372        0.865589   \n",
       "8  1.363450    0.041618     0.837508      0.833879        0.865323   \n",
       "9  1.494346    0.031833     0.841942      0.833264        0.865542   \n",
       "\n",
       "   train_precision  test_brier  train_brier  test_roc  train_roc  \n",
       "0         0.867010   -0.097278    -0.097660  0.925664   0.925042  \n",
       "1         0.866467   -0.097666    -0.097499  0.922222   0.925491  \n",
       "2         0.866891   -0.095724    -0.097921  0.929772   0.924527  \n",
       "3         0.867461   -0.100272    -0.097218  0.920181   0.925661  \n",
       "4         0.867097   -0.096262    -0.097793  0.926699   0.924912  \n",
       "5         0.867773   -0.101630    -0.097082  0.919651   0.925741  \n",
       "6         0.866360   -0.095957    -0.097815  0.926479   0.924942  \n",
       "7         0.867155   -0.100175    -0.097272  0.922438   0.925432  \n",
       "8         0.866998   -0.096360    -0.097794  0.927822   0.924812  \n",
       "9         0.866846   -0.095262    -0.097916  0.929233   0.924660  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Cross-validation\n",
    "scoring = {'recall': 'recall',\n",
    "           'precision': 'precision',\n",
    "           'brier': 'neg_brier_score',\n",
    "           'roc': 'roc_auc'\n",
    "          }\n",
    "scores = cross_validate(estimator=ridge,\n",
    "                         X=df_train[features],\n",
    "                         y=df_train[[\"satisfaction\"]],\n",
    "                         scoring=scoring,\n",
    "                         cv=10,\n",
    "                         n_jobs=-1,\n",
    "                         return_train_score=True)\n",
    "sorted(scores.keys())\n",
    "print(scores)\n",
    "display(pd.DataFrame(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f972ea2c",
   "metadata": {},
   "source": [
    "3) Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ca1cd69e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegressionCV(Cs=[0.1, 0.5, 1], l1_ratios=[0.1, 0.2, 0.5],\n",
       "                     penalty=&#x27;elasticnet&#x27;, random_state=123, solver=&#x27;saga&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegressionCV</label><div class=\"sk-toggleable__content\"><pre>LogisticRegressionCV(Cs=[0.1, 0.5, 1], l1_ratios=[0.1, 0.2, 0.5],\n",
       "                     penalty=&#x27;elasticnet&#x27;, random_state=123, solver=&#x27;saga&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegressionCV(Cs=[0.1, 0.5, 1], l1_ratios=[0.1, 0.2, 0.5],\n",
       "                     penalty='elasticnet', random_state=123, solver='saga')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Basic Elastic Net regularisation\n",
    "elasticnet = LogisticRegressionCV(penalty='elasticnet', solver='saga', l1_ratios=[0.1,0.2,0.5], Cs=[0.1,0.5,1], random_state=123) \n",
    "elasticnet.fit(x_train_scaled, y_train.Satisfaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c44f6f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.87430705\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89     14662\n",
      "           1       0.87      0.83      0.85     11314\n",
      "\n",
      "    accuracy                           0.87     25976\n",
      "   macro avg       0.87      0.87      0.87     25976\n",
      "weighted avg       0.87      0.87      0.87     25976\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_elasticnet = elasticnet.predict(x_test_scaled)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.8f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1af74d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Elastic Net Regularisation Accuracy: 0.68663683\n",
      "\n",
      "Logistic Regression Grid Search Results:\n",
      "Best C value (inverse regularization strength):  [0.00215443]\n",
      "Best l1_ratio (mix of L1 and L2 regularization):  [0.9]\n",
      "Best cross-validation accuracy: 0.87472781\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameter tuning \n",
    "elasticnet_alpha= np.logspace(-4, 0, 10)\n",
    "elasticnet_l1_ratio= [0.1, 0.25, 0.5, 0.75, 0.9]\n",
    "elasticnet_grid_search = LogisticRegressionCV(Cs=elasticnet_alpha, random_state=123, penalty='elasticnet', l1_ratios= elasticnet_l1_ratio, solver='saga', cv=10, scoring='accuracy')\n",
    "elasticnet_grid_search.fit(x_train_scaled, y_train.Satisfaction)\n",
    "elasticnet_grid_val_pred = elasticnet_grid_search.predict(x_val_scaled)\n",
    "\n",
    "print(f\"Tuned Elastic Net Regularisation Accuracy: {accuracy_score(y_val.Satisfaction, elasticnet_grid_val_pred):.8f}\") \n",
    "print(\"\\nLogistic Regression Grid Search Results:\")\n",
    "print(\"Best C value (inverse regularization strength): \", elasticnet_grid_search.C_)\n",
    "print(\"Best l1_ratio (mix of L1 and L2 regularization): \", elasticnet_grid_search.l1_ratio_)\n",
    "print(f\"Best cross-validation accuracy: {elasticnet_grid_search.score(x_train_scaled, y_train.Satisfaction):.8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0d219097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([51.20939016, 50.70993733, 51.50035691, 51.19717431, 53.40404725,\n",
      "       53.05607915, 51.60320067, 52.90582085, 27.52293444, 26.62883902]), 'score_time': array([0.07475495, 0.06845903, 0.11483264, 0.08697081, 0.05200481,\n",
      "       0.07001138, 0.0879426 , 0.07656622, 0.03002286, 0.04544067]), 'test_recall': array([0.83444149, 0.82845745, 0.84242021, 0.82823582, 0.83506983,\n",
      "       0.82664598, 0.83263135, 0.8308579 , 0.83750831, 0.84194192]), 'train_recall': array([0.83380129, 0.83439239, 0.83296389, 0.83392444, 0.83360835,\n",
      "       0.83464276, 0.83387927, 0.83434722, 0.83385464, 0.83341132]), 'test_precision': array([0.86831181, 0.87336449, 0.86840302, 0.86424607, 0.8677724 ,\n",
      "       0.86060466, 0.87328528, 0.86558891, 0.86532295, 0.86455725]), 'train_precision': array([0.86707305, 0.86644501, 0.86689052, 0.86777897, 0.86716028,\n",
      "       0.86774722, 0.86635449, 0.8671735 , 0.86701665, 0.86673326]), 'test_brier': array([-0.09727274, -0.09766555, -0.09572105, -0.10029927, -0.09625904,\n",
      "       -0.10162919, -0.09596073, -0.10017318, -0.09635789, -0.09529085]), 'train_brier': array([-0.09765477, -0.0974995 , -0.09791749, -0.09723901, -0.09779013,\n",
      "       -0.09708238, -0.09781687, -0.09726963, -0.09779171, -0.09794057]), 'test_roc': array([0.92566314, 0.92222388, 0.92977137, 0.92018321, 0.92670039,\n",
      "       0.91964885, 0.92647275, 0.92243643, 0.92782184, 0.92923556]), 'train_roc': array([0.92504326, 0.92549067, 0.9245278 , 0.92566293, 0.92491242,\n",
      "       0.92573896, 0.92493938, 0.92543191, 0.92481109, 0.92466363])}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_brier</th>\n",
       "      <th>train_brier</th>\n",
       "      <th>test_roc</th>\n",
       "      <th>train_roc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51.209390</td>\n",
       "      <td>0.074755</td>\n",
       "      <td>0.834441</td>\n",
       "      <td>0.833801</td>\n",
       "      <td>0.868312</td>\n",
       "      <td>0.867073</td>\n",
       "      <td>-0.097273</td>\n",
       "      <td>-0.097655</td>\n",
       "      <td>0.925663</td>\n",
       "      <td>0.925043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50.709937</td>\n",
       "      <td>0.068459</td>\n",
       "      <td>0.828457</td>\n",
       "      <td>0.834392</td>\n",
       "      <td>0.873364</td>\n",
       "      <td>0.866445</td>\n",
       "      <td>-0.097666</td>\n",
       "      <td>-0.097500</td>\n",
       "      <td>0.922224</td>\n",
       "      <td>0.925491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51.500357</td>\n",
       "      <td>0.114833</td>\n",
       "      <td>0.842420</td>\n",
       "      <td>0.832964</td>\n",
       "      <td>0.868403</td>\n",
       "      <td>0.866891</td>\n",
       "      <td>-0.095721</td>\n",
       "      <td>-0.097917</td>\n",
       "      <td>0.929771</td>\n",
       "      <td>0.924528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51.197174</td>\n",
       "      <td>0.086971</td>\n",
       "      <td>0.828236</td>\n",
       "      <td>0.833924</td>\n",
       "      <td>0.864246</td>\n",
       "      <td>0.867779</td>\n",
       "      <td>-0.100299</td>\n",
       "      <td>-0.097239</td>\n",
       "      <td>0.920183</td>\n",
       "      <td>0.925663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53.404047</td>\n",
       "      <td>0.052005</td>\n",
       "      <td>0.835070</td>\n",
       "      <td>0.833608</td>\n",
       "      <td>0.867772</td>\n",
       "      <td>0.867160</td>\n",
       "      <td>-0.096259</td>\n",
       "      <td>-0.097790</td>\n",
       "      <td>0.926700</td>\n",
       "      <td>0.924912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>53.056079</td>\n",
       "      <td>0.070011</td>\n",
       "      <td>0.826646</td>\n",
       "      <td>0.834643</td>\n",
       "      <td>0.860605</td>\n",
       "      <td>0.867747</td>\n",
       "      <td>-0.101629</td>\n",
       "      <td>-0.097082</td>\n",
       "      <td>0.919649</td>\n",
       "      <td>0.925739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>51.603201</td>\n",
       "      <td>0.087943</td>\n",
       "      <td>0.832631</td>\n",
       "      <td>0.833879</td>\n",
       "      <td>0.873285</td>\n",
       "      <td>0.866354</td>\n",
       "      <td>-0.095961</td>\n",
       "      <td>-0.097817</td>\n",
       "      <td>0.926473</td>\n",
       "      <td>0.924939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>52.905821</td>\n",
       "      <td>0.076566</td>\n",
       "      <td>0.830858</td>\n",
       "      <td>0.834347</td>\n",
       "      <td>0.865589</td>\n",
       "      <td>0.867174</td>\n",
       "      <td>-0.100173</td>\n",
       "      <td>-0.097270</td>\n",
       "      <td>0.922436</td>\n",
       "      <td>0.925432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>27.522934</td>\n",
       "      <td>0.030023</td>\n",
       "      <td>0.837508</td>\n",
       "      <td>0.833855</td>\n",
       "      <td>0.865323</td>\n",
       "      <td>0.867017</td>\n",
       "      <td>-0.096358</td>\n",
       "      <td>-0.097792</td>\n",
       "      <td>0.927822</td>\n",
       "      <td>0.924811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>26.628839</td>\n",
       "      <td>0.045441</td>\n",
       "      <td>0.841942</td>\n",
       "      <td>0.833411</td>\n",
       "      <td>0.864557</td>\n",
       "      <td>0.866733</td>\n",
       "      <td>-0.095291</td>\n",
       "      <td>-0.097941</td>\n",
       "      <td>0.929236</td>\n",
       "      <td>0.924664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fit_time  score_time  test_recall  train_recall  test_precision  \\\n",
       "0  51.209390    0.074755     0.834441      0.833801        0.868312   \n",
       "1  50.709937    0.068459     0.828457      0.834392        0.873364   \n",
       "2  51.500357    0.114833     0.842420      0.832964        0.868403   \n",
       "3  51.197174    0.086971     0.828236      0.833924        0.864246   \n",
       "4  53.404047    0.052005     0.835070      0.833608        0.867772   \n",
       "5  53.056079    0.070011     0.826646      0.834643        0.860605   \n",
       "6  51.603201    0.087943     0.832631      0.833879        0.873285   \n",
       "7  52.905821    0.076566     0.830858      0.834347        0.865589   \n",
       "8  27.522934    0.030023     0.837508      0.833855        0.865323   \n",
       "9  26.628839    0.045441     0.841942      0.833411        0.864557   \n",
       "\n",
       "   train_precision  test_brier  train_brier  test_roc  train_roc  \n",
       "0         0.867073   -0.097273    -0.097655  0.925663   0.925043  \n",
       "1         0.866445   -0.097666    -0.097500  0.922224   0.925491  \n",
       "2         0.866891   -0.095721    -0.097917  0.929771   0.924528  \n",
       "3         0.867779   -0.100299    -0.097239  0.920183   0.925663  \n",
       "4         0.867160   -0.096259    -0.097790  0.926700   0.924912  \n",
       "5         0.867747   -0.101629    -0.097082  0.919649   0.925739  \n",
       "6         0.866354   -0.095961    -0.097817  0.926473   0.924939  \n",
       "7         0.867174   -0.100173    -0.097270  0.922436   0.925432  \n",
       "8         0.867017   -0.096358    -0.097792  0.927822   0.924811  \n",
       "9         0.866733   -0.095291    -0.097941  0.929236   0.924664  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Cross-validation\n",
    "scoring = {'recall': 'recall',\n",
    "           'precision': 'precision',\n",
    "           'brier': 'neg_brier_score',\n",
    "           'roc': 'roc_auc'\n",
    "          }\n",
    "scores = cross_validate(estimator=elasticnet,\n",
    "                         X=df_train[features],\n",
    "                         y=df_train[[\"satisfaction\"]],\n",
    "                         scoring=scoring,\n",
    "                         cv=10,\n",
    "                         n_jobs=-1,\n",
    "                         return_train_score=True)\n",
    "sorted(scores.keys())\n",
    "print(scores)\n",
    "display(pd.DataFrame(scores)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2ecf06",
   "metadata": {},
   "source": [
    "Final conclusion: the usage of Lasso/Ridge/Elastic Net regularisation leads to decrease in accuracy, therefore it shouldn't be applied to this model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
